# LLM Finetuning Cookbook

ğŸ”¥ A hands-on, code-first collection of recipes for fine-tuning Large Language Models. ğŸ”¥

This repository is not a polished library but a collection of practical, well-commented notebooks and scripts. The goal is to provide deep insights into the code and mechanics behind various LLM fine-tuning techniques

---

## ğŸ“– Table of Contents

This cookbook is divided into several key fine-tuning methodologies. Each section contains dedicated code, explanations, and links to relevant resources.

1.  [**ğŸ“š Full Fine-Tuning (From Scratch)**](./01-Full-Fine-Tuning/): Modifying every weight in the model. The most thorough but resource-intensive method.
2.  [**âš¡ Parameter-Efficient Fine-Tuning (PEFT)**](./02-PEFT/): Smart techniques to fine-tune LLMs with a fraction of the computational cost.
3.  [**ğŸ¯ Instruction & Task Fine-Tuning**](./03-Instruction-Tuning/): Teaching a model to follow instructions and perform specific tasks like summarization or sentiment analysis.
4.  [**ğŸ§  Reasoning Fine-Tuning**](./04-Reasoning-Tuning/): Enhancing a model's ability to perform logical, mathematical, or multi-step reasoning.

---

### **1. ğŸ“š Full Fine-Tuning (From Scratch)**

In this section, we explore the foundational approach of training all of the model's parameters on a new dataset. This is ideal for adapting a model to a completely new domain or style.

**Featured Recipe: Training GPT-2 From Scratch**
* **Description**: A step-by-step guide to pre-training a GPT-2 model from the ground up on the `openwebtext` dataset.
* **Key Concepts Covered**:
    * Loading and streaming large datasets with `Deep Lake`.
    * Configuring model architecture (`n_layer`, `n_head`, `n_embd`).
    * Setting up the `Hugging Face Trainer` and `TrainingArguments`.
    * Running the training loop and performing inference.
* **Code**: [`./01-Full-Fine-Tuning/GPT-2-From-Scratch.ipynb`](./01-Full-Fine-Tuning/GPT-2-From-Scratch.ipynb)

---

### **2. âš¡ Parameter-Efficient Fine-Tuning (PEFT)**

PEFT methods allow us to achieve great performance by only training a small subset of the model's parameters. This makes fine-tuning accessible without high-end hardware.

**Featured Recipe: Fine-tuning Falcon-7B with LoRA**
* **Description**: Use Low-Rank Adaptation (LoRA) to efficiently fine-tune the powerful Falcon-7B model on a custom dataset.
* **Key Concepts Covered**:
    * **Quantization**: Loading models in 4-bit using `BitsAndBytesConfig` to save memory.
    * **LoRA Configuration**: Setting up `LoraConfig` from the `peft` library (`r`, `lora_alpha`, `target_modules`).
    * **SFTTrainer**: Using the Supervised Fine-Tuning trainer from the `trl` library for simplified training.
* **Code**: [`./02-PEFT/Falcon-7B-LoRA.ipynb`](./02-PEFT/Falcon-7B-LoRA.ipynb)

---

### **3. ğŸ¯ Instruction & Task Fine-Tuning**

This is the most common type of fine-tuning, where we teach a base model to act as a helpful assistant for specific tasks by training it on instruction-response pairs.

**Featured Recipes:**
1.  **Summarization with FLAN-T5**:
    * **Description**: Fine-tune Google's FLAN-T5 on the `dialogsum` dataset to make it an expert summarizer. Compares full fine-tuning vs. PEFT (LoRA).
    * **Key Concepts**: Data preprocessing for instruction-following, evaluating with the ROUGE metric.
    * **Code**: [`./03-Instruction-Tuning/Summarization-FLAN-T5.ipynb`](./03-Instruction-Tuning/Summarization-FLAN-T5.ipynb)

2.  **Financial Sentiment Analysis with OPT-1.3b**:
    * **Description**: Adapt the OPT-1.3b model to understand financial news sentiment.
    * **Key Concepts**: Domain-specific adaptation, combining LoRA with instruction tuning for a specialized task.
    * **Code**: [`./03-Instruction-Tuning/Financial-Sentiment-OPT.ipynb`](./03-Instruction-Tuning/Financial-Sentiment-OPT.ipynb)

---

### **4. ğŸ§  Reasoning Fine-Tuning**

A more advanced topic focused on improving a model's ability to "think" through complex problems, from math puzzles to logical deductions.

**Featured Recipe: Mathematical Reasoning with Qwen & GRPO**
* **Description**: Enhance the mathematical capabilities of the Qwen model using advanced techniques like Generalized Reward Policy Optimization (GRPO).
* **Key Concepts Covered**:
    * Using specialized datasets for reasoning tasks.
    * Leveraging high-performance libraries like `Unsloth` for faster training.
    * Implementing advanced optimization techniques beyond standard fine-tuning.
* **Code**: [`./04-Reasoning-Tuning/Math-Reasoning-Qwen-GRPO.ipynb`](./04-Reasoning-Tuning/Math-Reasoning-Qwen-GRPO.ipynb)

---

## ğŸ“‚ Project Structure

```
LLM-Finetuning-Cookbook/
â”‚
â”œâ”€â”€ 01-Full-Fine-Tuning/
â”‚   â”œâ”€â”€ GPT-2-From-Scratch.ipynb
â”‚   â””â”€â”€ README.md                      # Detailed guide for this section
â”‚
â”œâ”€â”€ 02-PEFT/
â”‚   â”œâ”€â”€ Falcon-7B-LoRA.ipynb
â”‚   â””â”€â”€ README.md                      # LoRA, QLoRA techniques explained
â”‚
â”œâ”€â”€ 03-Instruction-Tuning/
â”‚   â”œâ”€â”€ Summarization-FLAN-T5.ipynb
â”‚   â”œâ”€â”€ Financial-Sentiment-OPT.ipynb
â”‚   â””â”€â”€ README.md                      # Instruction tuning best practices
â”‚
â”œâ”€â”€ 04-Reasoning-Tuning/
â”‚   â”œâ”€â”€ Math-Reasoning-Qwen-GRPO.ipynb
â”‚   â””â”€â”€ README.md                      # Advanced reasoning techniques
â”‚
â”œâ”€â”€ .devcontainer/
â”‚   â””â”€â”€ devcontainer.json              # VS Code Dev Container config
â”‚
â”œâ”€â”€ pyproject.toml                     # Poetry dependency management
â”œâ”€â”€ Dockerfile                         # Multi-stage Docker build
â”œâ”€â”€ docker-compose.yml                 # Container orchestration
â”œâ”€â”€ Makefile                          # Convenient commands
â”œâ”€â”€ .pre-commit-config.yaml           # Code quality hooks
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ SETUP.md                          # ğŸ“– Complete setup guide
â”œâ”€â”€ CONTRIBUTING.md                   # ğŸ¤ Contribution guidelines
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Quick Start (3 Options)

Choose your preferred setup method:

#### ğŸ”· Option 1: Local Setup with Poetry (Recommended)

```bash
# Clone repository
git clone https://github.com/your-username/LLM-Finetuning-Cookbook.git
cd LLM-Finetuning-Cookbook

# Install Poetry (if not already installed)
curl -sSL https://install.python-poetry.org | python3 -

# Install all dependencies
make install-all

# Start Jupyter Lab
make jupyter
```

#### ğŸ³ Option 2: Docker Setup (Zero Configuration)

```bash
# Clone and start with Docker
git clone https://github.com/your-username/LLM-Finetuning-Cookbook.git
cd LLM-Finetuning-Cookbook

# Build and run
make docker-build
make docker-up

# Open http://localhost:8888
```

#### ğŸ’» Option 3: VS Code Dev Containers (Best IDE Integration)

1. Install Docker and the "Dev Containers" extension
2. Open repository in VS Code
3. Press `F1` â†’ "Dev Containers: Reopen in Container"
4. Everything is configured automatically!

### Detailed Setup Instructions

For comprehensive setup guides, troubleshooting, and advanced configurations, see:

ğŸ“– **[SETUP.md](SETUP.md)** - Complete installation guide for all methods

### Prerequisites

* **Python 3.10+**
* **Poetry** (for local setup)
* **Docker** (for containerized setup)
* **NVIDIA GPU** (highly recommended for training)
* **CUDA 12.1+** (if using GPU)

---

## ğŸ¯ Selective Installation

Don't need everything? Install only what you need:

```bash
# Core dependencies only
make install

# Add specific sections as needed
make install-full-finetuning    # For 01-Full-Fine-Tuning
make install-peft               # For 02-PEFT  
make install-instruction-tuning # For 03-Instruction-Tuning
make install-reasoning          # For 04-Reasoning-Tuning

# Or combine multiple
poetry install --with peft,instruction-tuning
```

---

## ğŸ› ï¸ Useful Commands

```bash
# Development
make jupyter           # Start Jupyter Lab
make format           # Format code with black & isort
make lint             # Run linters
make clean            # Clean up generated files

# Docker
make docker-build     # Build Docker image
make docker-up        # Start containers
make docker-down      # Stop containers
make docker-shell     # Open shell in container

# Maintenance
make lock             # Update poetry.lock
make update           # Update dependencies
```

---

## ğŸ—ï¸ Repository Design Patterns

This repository follows modern best practices:

### âœ… Dependency Management
- **Poetry** with dependency groups for modular installations
- Single `pyproject.toml` as source of truth
- Locked dependencies for reproducibility

### âœ… Containerization
- Multi-stage Dockerfile (dev/prod)
- Docker Compose for orchestration
- VS Code Dev Containers for seamless development
- GPU support with NVIDIA Docker

### âœ… Code Quality
- Pre-commit hooks (black, isort, flake8)
- Automated formatting and linting
- Type hints where applicable
- Clean notebook outputs before commits

### âœ… Documentation
- Comprehensive README per section
- Detailed setup guide (SETUP.md)
- Contributing guidelines (CONTRIBUTING.md)
- Inline comments in all notebooks

### âœ… Professional Structure
- Consistent notebook formatting
- Modular dependencies
- Easy CI/CD integration
- Beginner to advanced friendly

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:

- How to add new notebooks
- Code quality standards
- Testing guidelines
- Pull request process

**Quick contribution setup:**
```bash
make setup-dev  # Install dev dependencies + pre-commit hooks
```

---

## ğŸ™ Acknowledgements

A huge thank you to **Youssef Hosni** for his clear, detailed, and practical articles that form the inspiration for this repository. Please check out his work:

* **GitHub**: [youssefHosni/Hands-On-LLM-Fine-Tuning](https://github.com/youssefHosni/Hands-On-LLM-Fine-Tuning)
* **Medium**: [Youssef Hosni's Articles](https://youssef-hosni.medium.com/)

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
